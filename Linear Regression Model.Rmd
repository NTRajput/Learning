---
title: 'Linear Regression Model '
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

####  Business Analytics
###Regression Models

+ define X and Y variables

##1 a)
++plot Y against  X - in terms of the two variables plot we can easily recognise that a fit line ot we can say that a linear moder to explain y based on x can be employed here .
++fit an abline o the plot of the two variables
++simple linear model of Y based on X 
++Summary of model 
```{r}
set.seed(2017)
X=runif(100)*10
Y=X*4+3.45
Y=rnorm(100)*0.29*Y+Y
library("dplyr")
library("stats")
plot(Y,X,col= "RED")
abline(lsfit(Y,X))
```
##1 b)
++a simple linear model of Y based on X
++equation that explains Y based on X.
```{r}
linearmodel = lm(Y~X)
Y_cap  = 4.465 + 3.611*X
Y_cap
print(linearmodel)
summary(linearmodel)
```
##1 c) R2, of the model above is related to the correlation coefficient of X and Y
+R^2 the 0.6517  which means the linear model  explains 65.17% variability the target (response) variable i.e. X is a good  predictor of the variable Y 
+Accuracy of the model is R-square= 0.6517 (65.17%) 

##1 d)Checking appropriateness of using linear regression for this case using indicator :
++histogram of the residuals
++normal qualtile plot 
```{r}
linearmodel$residuals
hist(linearmodel$residuals)
qqnorm(linearmodel$residuals,col="blue")
qqline(linearmodel$residuals)
```
##results Interpretation 
By plotting the residuals histogram and qqplot line, we can see the that residual errors are normally distributed which satisfies one assumption of linear regression for normality, Therefore Linear regression approach is appropiate. 
the above two plots of the residuals confirm that the distribution is normal thus the regression model is fit for this data and R^2 is a good estimator of the model accuracy here.

##2a) Regression model to test relation between :
++weight of a car (wt) as an estimator of cars the Horse Power Vs.
++fuel consumption expressed in Mile Per Gallon (mpg), as an estimator of the (hp)
```{r}
#linear model with weight as an estimator of hp
reg_wt <-lm(hp ~ wt, data = mtcars)
summary(reg_wt)
hist(reg_wt$residuals)
qqnorm(reg_wt$residuals, xlab = "wt", ylab ="hp",col="blue")
qqline(reg_wt$residuals)
#linear model with mpg as an estimator of hp
reg_mpg <-lm(hp ~ mpg, data = mtcars)
summary(reg_mpg)
hist(reg_mpg$residuals)
qqnorm(reg_mpg$residuals,xlab = "mpg", ylab ="hp",col="blue")
qqline(reg_mpg$residuals)

```
##Results interpretation :
++the R^2 of linear model of HP ~ mpg and the histogram of the residuals of this model and the qq plot of the residuals of this model all three of them indicate that mpg is a better estimator of the car's Horsepower
++R square of the hp~mpg model is less than that of hp~wt model and it assures the model accuracy of 60% while the other r square only predicts the model accuracy as 40%
++car weight does not contribute much towards predicted horse power of the car, As car weight is not statistically significant based on the pvalue. However fuel consumption in mile per gallon contributes in better predictor of car horse power.therefore chris assumption is correct. 
## thus chris is right !

##2 b)model that uses the number of cylinders (cyl) and the mile per gallon (mpg) values of a car to predict the car Horse Power (hp). 

##
```{r}
reg_cylmpg = lm(hp ~ cyl + mpg, data = mtcars)
summary(reg_cylmpg)
```
## estimated Horse Power of a car with 4 cylinder and mpg of 22
```{r}
hp_pediction <- predict(reg_cylmpg,data.frame(cyl = c(4),mpg=c(22)))
hp_pediction 
```

##85% confidence interval
```{r}
predict(reg_cylmpg,data.frame(cyl = c(4),mpg=c(22)),interval = "prediction",level=0.85)
```

##3 lets get the data set for use in this part - Bostonhousing and relavnt library
```{r}
library("mlbench")
data(BostonHousing)
```


##3 a) A model to estimate the median value of owner-occupied homes (medv)based on the following variables:
crime crate (crim), proportion of residential land zoned for lots over 25,000 sq.ft (zn),the local pupil-teacher ratio (ptratio) and weather the whether the tract bounds Chas River(chas).
```{r}
reg_housing = lm (medv ~ crim + zn + ptratio + chas, data = BostonHousing)
summary(reg_housing)
```
##test- accuracy of model 

+ the model accuracy is only 35.99% which indicates the model is not very strong but average.


```{r}
hist(reg_housing$residuals)
qqnorm(reg_housing$residuals,xlab= "crim,zn,ptratio,chas-residuals", ylab = "medv",col="blue")
qqline(reg_housing$residuals)
```
+however the histograms of the residuals and the qq plot shows a normal distribution for the residual , the model is relevant to be used here . 

##Further evidence for variables to be a good estimator of the medv ?
```{r}
reg_housing1 = lm (medv ~ crim + zn + ptratio, data = BostonHousing)
summary(reg_housing1)
reg_housing2 = lm (medv ~ crim + zn, data = BostonHousing)
summary(reg_housing2)
reg_housing3 = lm (medv ~ crim, data = BostonHousing)
summary(reg_housing3)
```
##Results Interpretation :
+ we added the variable is an increasing fashion and every time the R square value kept increasing it was the least in reg_housing3 only one variable of crime ,R square = 0.1508 and the most in the model with all four variables 
R square= 0.3599 thus ,adding other three improves the model accuracy. 

##3 b)price om basis of house being in the bounds the Chas River or not 
+ chas variable is binary thus in the model the values of 0 i.e. not near chas is ingnored 
+ from thr model summary: chas1        4.58393    1.31108   3.496 0.000514 *** 
House bounds to chas river would be more expensive  than that which does not, because based on linear regression model chas is statistically significant in estimating the median house price. also model indicates with 
medv  = 49.91868 +  4.58393*chas1

##3 b)price if  the pupil-teacher ratio is 15 and in the other one is 18

```{r}
houseprice1 = 49.91868 + (-1.49367*15)
houseprice1
houseprice2 = 49.91868 + (-1.49367*18)
houseprice2
```
##Result interpretation: as the coefficeint of ptration is in negative thsu means if the ratio value is higher the house price would be less and if its less the houseprice would be more.


##3 c) statistically important variable :
+most statistically important variable are crime rate and pratio - they are explained as lower valuesin them will lead to greater house price which makes sense in genral too-  terms of the crime rate ratio and the ptratio is represenative of only this dataset .
##3 d) Anova Analysis to determine the order of importance of these four variables.
```{r}
anova(reg_housing)
```

##Results Interpretation:
We can see that the variability (sum squared) explained by the crime variable is significantly higher than that of zn or chas. We could guess this as adding the crime,ptratio, and zn  significantly improved the model.Also we can see the least indicative variable is chas which is the location in river bounds and then the zone. Still we can see that a large portion of the variability is unexplained, that is shown by residuals 27344.5 so by further adding more relevant variables we might be able to get a better prediction model.

